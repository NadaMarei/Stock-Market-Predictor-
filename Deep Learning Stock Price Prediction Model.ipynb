{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2340980a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yfinance in c:\\users\\user\\anaconda3\\lib\\site-packages (0.2.42)\n",
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (2.32.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (5.2.1)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (3.17.6)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\anaconda3\\lib\\site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.31->yfinance) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "# Installs the yfinance library, which allows easy access to historical market data from Yahoo Finance.\n",
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7e9287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\user\\anaconda3\\lib\\site-packages (1.32.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (5.3.3)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (1.26.4)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (10.3.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (14.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (2.32.2)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (13.3.5)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (8.2.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (4.11.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (3.1.37)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from streamlit) (4.0.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
      "Requirement already satisfied: toolz in c:\\users\\user\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.15.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Installs the streamlit library for building the user interface of the model.\n",
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "495f01b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fundamental package for numerical computations in Python.\n",
    "import numpy as np\n",
    "\n",
    "# A library used for data manipulation and analysis, especially for handling data in DataFrame format.\n",
    "import pandas as pd\n",
    "\n",
    "# library to download historical stock price data.\n",
    "import yfinance as yf\n",
    "\n",
    "# the load_model function from Keras, which is used to load a pre-trained deep learning model.\n",
    "from keras.models import load_model\n",
    "\n",
    "# create a web-based user interface.\n",
    "import streamlit as st\n",
    "\n",
    "# create plots and visualizations.\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32807f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low      Close  Adj Close     Volume\n",
      "Date                                                                        \n",
      "2012-01-03  16.262545  16.641375  16.248346  16.573130  16.554291  147611217\n",
      "2012-01-04  16.563665  16.693678  16.453827  16.644611  16.625692  114989399\n",
      "2012-01-05  16.491436  16.537264  16.344486  16.413727  16.395069  131808205\n",
      "2012-01-06  16.417213  16.438385  16.184088  16.189817  16.171415  108119746\n",
      "2012-01-09  16.102144  16.114599  15.472754  15.503389  15.485767  233776981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the start and end dates\n",
    "start = '2012-01-01'\n",
    "end = '2025-08-11'\n",
    "\n",
    "# Define the stock ticker symbol, This ticker symbol is used to download the stock data.\n",
    "stock = 'GooG'\n",
    "\n",
    "try:\n",
    "    # Downloads the stock data for the specified ticker within the defined date range.\n",
    "    data = yf.download(stock, start=start, end=end)\n",
    "    \n",
    "    # Downloads the stock data for the specified ticker within the defined date range.\n",
    "    if data.empty:\n",
    "        #If the data is empty, print a message indicating no data was found.\n",
    "        print(f\"No data found for ticker {stock}.\")\n",
    "        \n",
    "    # If data is successfully downloaded, proceed to print the first few rows.\n",
    "    else:\n",
    "        print(data.head())  # Display the first 5 rows of data to verify that it has been downloaded correctly.\n",
    "\n",
    "# Catches any exceptions that occur during data download.\n",
    "except Exception as e: \n",
    "    print(f\"Failed to download data: {e}\") # Prints an error message if the data download fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "349376d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low      Close  Adj Close     Volume\n",
      "Date                                                                        \n",
      "2012-01-03  16.262545  16.641375  16.248346  16.573130  16.554291  147611217\n",
      "2012-01-04  16.563665  16.693678  16.453827  16.644611  16.625692  114989399\n",
      "2012-01-05  16.491436  16.537264  16.344486  16.413727  16.395069  131808205\n",
      "2012-01-06  16.417213  16.438385  16.184088  16.189817  16.171415  108119746\n",
      "2012-01-09  16.102144  16.114599  15.472754  15.503389  15.485767  233776981\n",
      "2012-01-10  15.684959  15.785831  15.365158  15.520326  15.502685  176483032\n",
      "2012-01-11  15.529292  15.675993  15.470015  15.590563  15.572842   96359832\n",
      "2012-01-12  15.721572  15.763166  15.604012  15.682219  15.664393   75289148\n",
      "2012-01-13  15.598035  15.615220  15.468520  15.566403  15.548710   92637933\n",
      "2012-01-17  15.740501  15.740501  15.583589  15.655818  15.638022   76658261\n"
     ]
    }
   ],
   "source": [
    "# Display the first 10 rows of the data to verify the download\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7537ee4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High         Low       Close   Adj Close  \\\n",
      "Date                                                                     \n",
      "2024-08-23  166.550003  167.949997  165.660004  167.429993  167.429993   \n",
      "2024-08-26  168.154999  169.380005  166.320007  167.929993  167.929993   \n",
      "2024-08-27  167.610001  168.244995  166.160004  166.380005  166.380005   \n",
      "2024-08-28  166.779999  167.389999  163.279999  164.500000  164.500000   \n",
      "2024-08-29  166.059998  167.630005  161.981995  163.399994  163.399994   \n",
      "2024-08-30  164.220001  165.279999  163.410004  165.110001  165.110001   \n",
      "2024-09-03  163.315002  163.380005  157.854996  158.610001  158.610001   \n",
      "2024-09-04  158.074997  160.399994  157.440002  157.809998  157.809998   \n",
      "2024-09-05  157.779999  161.014999  157.520004  158.600006  158.600006   \n",
      "2024-09-06  158.690002  159.220001  151.934998  152.130005  152.130005   \n",
      "\n",
      "              Volume  \n",
      "Date                  \n",
      "2024-08-23  14281600  \n",
      "2024-08-26  11990300  \n",
      "2024-08-27  13718200  \n",
      "2024-08-28  15208700  \n",
      "2024-08-29  17133800  \n",
      "2024-08-30  18498800  \n",
      "2024-09-03  26508900  \n",
      "2024-09-04  17410700  \n",
      "2024-09-05  14139500  \n",
      "2024-09-06  24984200  \n"
     ]
    }
   ],
   "source": [
    "# Displays the last 10 rows of the downloaded stock data to inspect the most recent data points.\n",
    "print(data.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "85e4e987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.Close: Accesses the 'Close' prices from the downloaded stock data.\n",
    "# rolling(100): Creates a rolling window of 100 days over the 'Close' prices.\n",
    "# mean(): Calculates the mean of the 'Close' prices within each 100-day window, effectively creating a 100-day moving average.\n",
    "# ma_100_days: Stores the calculated 100-day moving average of the 'Close' prices.\n",
    "\n",
    "\n",
    "# Calculate the 100-day moving average of the stock's closing prices for trend analysis.\n",
    "ma_100_days = data.Close.rolling(100).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the matplotlib backend to TkAgg to ensure plots are displayed correctly in a separate window.\n",
    "plt.switch_backend('TkAgg')\n",
    "\n",
    "# Creates a new figure for plotting with a specified size of 8 inches by 6 inches. The figsize parameter controls the dimensions of the plot.\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# Plot the 100-day moving average in red and label it as '100 Days MA'.\n",
    "plt.plot(ma_100_days, 'r', label='100 Days MA')\n",
    "\n",
    "# Plot the closing prices in green and label it as 'Close Price'.\n",
    "plt.plot(data.Close, 'g', label='Close Price')\n",
    "\n",
    "# Add a legend to the plot to differentiate between the 100-day moving average and the closing price. \n",
    "plt.legend()\n",
    "\n",
    "# Add a title and labels to the x-axis (Year) and y-axis (Price) to make the plot more informative.\n",
    "plt.title('100 Days Moving Average and Close Price')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# Render and display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587e668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the 200-day moving average of the stock's closing prices\n",
    "# used in conjunction with other moving averages or indicators to make informed trading decisions or to understand the long-term trend of a stock's price.\n",
    "ma_200_days = data.Close.rolling(200).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ee92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure with a size of 8x6 inches for plotting moving averages and closing prices.\n",
    "fig2 = plt.figure(figsize=(8,6))\n",
    "\n",
    "# Plot the 100-day moving average in red and label it as '100 Days MA'.\n",
    "plt.plot(ma_100_days, 'r', label='100 Days MA')\n",
    "\n",
    "# Plot the 200-day moving average in blue and label it as '200 Days MA'.\n",
    "plt.plot(ma_200_days, 'b',  label='200 Days MA')\n",
    "\n",
    "# Plot the actual closing prices in green and label it as 'Close Price'.\n",
    "plt.plot(data.Close, 'g', label='Close Price')\n",
    "\n",
    "# Add a legend to differentiate between the 100-day moving average, 200-day moving average, and closing prices.\n",
    "plt.legend()\n",
    "\n",
    "# Add a title and labels to the x-axis (Year) and y-axis (Price) for clarity.\n",
    "plt.title('100 and 200 Days Moving Average and Close Price')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# Display the plot showing the 100-day and 200-day moving averages along with the closing prices.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any rows with missing values from the dataset to ensure clean data.\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1220385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (first 80%) and testing (remaining 20%) sets based on the closing prices.\n",
    "data_train = pd.DataFrame(data.Close[0: int(len(data)*0.80)])\n",
    "data_test = pd.DataFrame(data.Close[int(len(data)*0.80): len(data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c873ecdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first and last 5 rows of the data set and the sape of the number of observations and features. \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cbda5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of data points in the training datasets.\n",
    "data_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77202ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of data points in the testing datasets.\n",
    "data_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2855869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  library that provides tools for machine learning in Python.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# This scaler normalizes the data, scaling each feature to a specified range (0 to 1 in this case).\n",
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f26e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training data to the range [0, 1] using MinMaxScaler\n",
    "data_train_scale = scaler.fit_transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a726e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences of 100 data points (features) and corresponding target values for training the LSTM model, \n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(100, data_train_scale.shape[0]):\n",
    "    x.append(data_train_scale[i-100:i])\n",
    "    y.append(data_train_scale[i,0])\n",
    "    \n",
    "# Convert the lists to NumPy arrays.\n",
    "x,y = np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec2ae99",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "- `Data Cleaning`: The data is first cleaned by dropping any missing values.\n",
    "- `Data Splitting`: The data is split into training (80%) and testing (20%) sets based on the closing prices.\n",
    "- `Data Normalization`: The training data is then scaled to a range of [0, 1] using MinMaxScaler (although the code mistakenly scales the test data instead of the training data).\n",
    "- `Sequence Preparation`: Finally, sequences of 100 consecutive data points are prepared for the LSTM model, with the next data point in the sequence serving as the target value. These sequences are then converted into NumPy arrays, ready for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb066b50",
   "metadata": {},
   "source": [
    "#### The below block of code builds a deep learning model using Keras, specifically an LSTM (Long Short-Term Memory) network, which is commonly used for time series forecasting like stock price prediction.\n",
    "\n",
    "\n",
    "#### Explanation of Importing the necessary modules from Keras to build the LSTM model:\n",
    "\n",
    "- `Sequential`: This is a linear stack of layers in Keras, where we can add layers sequentially to build the model.\n",
    "- `LSTM`: This layer is an LSTM network layer, which is designed to handle sequential data and capture long-term dependencies.\n",
    "- `Dropout`: This layer helps to prevent overfitting by randomly setting a fraction of input units to 0 at each update during training.\n",
    "- `Dense`: This is a regular densely connected neural network layer, used as the output layer in this case.\n",
    "- `Input`: Used to define the shape of the input data in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e9d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules from Keras to build the LSTM model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, Dense, Input\n",
    "\n",
    "# allows us to add layers one by one in a sequential order.\n",
    "model = Sequential()\n",
    "\n",
    "# Define the input shape for the LSTM model, specifying 100 time steps and 1 feature per step.\n",
    "# x.shape[1] corresponds to the number of time steps (which is 100, based on the data preparation earlier)\n",
    "# 1 indicates that there's one feature (the scaled closing price).\n",
    "model.add(Input(shape=(x.shape[1], 1))) \n",
    "\n",
    "# Add the first LSTM layer with 50 neurons, ReLU (Rectified Linear Unit) activation, \n",
    "# and sequence return enabled indicates that the LSTM layer should return the full sequence of outputs for the next LSTM layer.\n",
    "model.add(LSTM(units=50, activation='relu', return_sequences=True))\n",
    "\n",
    "# Dropout layer with a 20% dropout rate, meaning that 20% of the neurons will be randomly dropped during training to prevent overfitting.\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Add the second LSTM layer with 60 units and a Dropout layer with a 30% dropout rate.\n",
    "model.add(LSTM(units=60, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Add the third LSTM layer with 80 units and a Dropout layer with a 40% dropout rate.\n",
    "model.add(LSTM(units=80, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# Add the fourth and final LSTM layer with 120 units and a Dropout layer with a 50% dropout rate.\n",
    "model.add(LSTM(units=120, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Adds a Dense (fully connected) output layer with 1 neuron, \n",
    "# which will output the predicted value (the next day's stock price in this case).\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febc740",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "##### Model Architecture:\n",
    "- The model consists of four LSTM layers, each with increasing numbers of units (50, 60, 80, 120), followed by Dropout layers to prevent overfitting.\n",
    "- The return_sequences=True in the first three LSTM layers ensures that each layer passes the entire sequence of outputs to the next LSTM layer.\n",
    "- The final LSTM layer outputs only the last value in the sequence, which is passed to a Dense layer to make the prediction.\n",
    "- The Dropout rates increase with each layer to further mitigate overfitting, culminating in a final Dropout rate of 50%.\n",
    "\n",
    "##### This architecture is designed to capture the temporal dependencies in the stock price data, and the final model output will be the predicted stock price for the next time step based on the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ffbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(): This method configures the model for training.\n",
    "# optimizer='adam': Specifies the optimizer to use during training. In this case, it's the Adam optimizer, which is an adaptive learning rate optimization algorithm that is popular for training deep learning models due to its efficiency and low memory requirements.\n",
    "# loss='mean_squared_error': Specifies the loss function. The Mean Squared Error (MSE) is used here, which measures the average squared difference between the predicted and actual values.\n",
    "\n",
    "\n",
    "# Compile the model with the Adam optimizer and mean squared error as the loss function.\n",
    "model.compile(optimizer = 'adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575c8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An epoch is one complete pass through the entire training dataset. Here, the model will be trained for 50 epochs.\n",
    "# batch_size=32: Specifies the number of samples per gradient update. Here, 32 samples will be processed before the model's weights are updated.\n",
    "# verbose=1 means that progress and training metrics will be printed to the console for each epoch.\n",
    "\n",
    "\n",
    "# Train the model on the input data x and target values y for 50 epochs, using a batch size of 32, with verbose output enabled.\n",
    "model.fit(x,y, epochs= 50, batch_size =32, verbose =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d78ebfd",
   "metadata": {},
   "source": [
    "#### Summary:\n",
    "\n",
    "#### Model Compilation:\n",
    "\n",
    "- `The model is compiled` using the Adam optimizer and Mean Squared Error as the loss function, which is well-suited for regression tasks like stock price prediction.\n",
    "Model Training:\n",
    "\n",
    "- `The model is trained` on the input data for 50 epochs. During each epoch, the data is processed in batches of 32 samples. The training progress is displayed on the console, providing feedback on the loss value at each epoch.\n",
    "Learning Process:\n",
    "\n",
    "- `The model will adjust` its weights over 50 epochs to minimize the mean squared error between its predictions and the actual stock prices. The Adam optimizer helps in efficiently updating the weights based on the calculated gradients during each batch of training.\n",
    "\n",
    "#### This process is essential for teaching the LSTM model to recognize patterns in the historical stock price data and make predictions about future prices.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0621048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates a summary of the model architecture in the deep learning model (Details about each layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095b288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last 100 rows from the data_train DataFrame, representing the past 100 days of data.\n",
    "pas_100_days = data_train.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the last 100 rows from the training data with the test data,\n",
    "# ensuring the model has access to recent history when making predictions on the test set.\n",
    "data_test= pd.concat([pas_100_days, data_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29529ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169aaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_100_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab65ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the test data using the previously defined scaler. This involves both fitting the scaler\n",
    "# to the test data to compute necessary statistics (like min and max values) and then transforming\n",
    "# the data accordingly. The result is stored in data_test_scale.\n",
    "data_test_scale = scaler.fit_transform(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c42ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the input sequences (x) and corresponding target values (y) for the model.\n",
    "# The input sequences consist of 100 time steps, and the target value is the next time step's value.\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for i in range(100, data_test_scale.shape[0]):\n",
    "    # Append the sequence of the last 100 time steps to x\n",
    "    x.append(data_test_scale[i-100:i])\n",
    "    # Append the corresponding target value (the current time step's value) to y\n",
    "    y.append(data_test_scale[i, 0])\n",
    "\n",
    "# Convert the lists to NumPy arrays for efficient processing\n",
    "x, y = np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d73d056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained LSTM model to predict the next value in the time series for each sequence in x.\n",
    "# The predictions are stored in the y_predict array.\n",
    "y_predict = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35f7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the scaling factors applied to each feature during the scaling process.\n",
    "# This attribute stores the scale values as a NumPy array.\n",
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b1c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 1/scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9720da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = y_predict * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a0f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y * scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e676a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,8)) \n",
    "plt.plot(data.index[-len(y_predict):],y_predict, color='red', linestyle='dashed', label = 'Predicted Price')\n",
    "plt.plot(data.index[-len(y):],y , color='blue', label = 'Original Price') \n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Stock Price Predictions vs Original Values')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ce764",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Stock Prediction Model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
